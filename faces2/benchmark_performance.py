#!/usr/bin/env python3
"""
ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸
ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ, íŠ¹ì§• ì¶”ì¶œ, ë²¡í„° ì„ë² ë”©, DB ì €ì¥, ìœ ì‚¬ë„ ê²€ìƒ‰ì˜ í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
"""

import time
import os
from pathlib import Path
from core_backend import (
    IntegratedFaceSystem, FaceAnalyzer, FaceEmbedder,
    DatabaseManager, SystemConfig
)

def benchmark_performance():
    """ê° ë‹¨ê³„ë³„ ì„±ëŠ¥ ì¸¡ì •"""

    print("=" * 70)
    print("  ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ - Face Processing System")
    print("=" * 70)
    print()

    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    print("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    system = IntegratedFaceSystem()
    if not system.initialize():
        print("âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")
        return

    analyzer = FaceAnalyzer()
    embedder = FaceEmbedder()

    # ê¸°ì¡´ ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
    face_files = list(Path(system.config.faces_dir).rglob("*.jpg"))[:10]  # ì²˜ìŒ 10ê°œë§Œ í…ŒìŠ¤íŠ¸

    if not face_files:
        print("âŒ í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"âœ… í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ {len(face_files)}ê°œ ë°œê²¬\n")

    # 1. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì„±ëŠ¥ ì¸¡ì •
    print("1ï¸âƒ£  ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì„±ëŠ¥ ì¸¡ì •")
    print("-" * 70)
    download_times = []

    print("   ë‹¤ìš´ë¡œë“œ 3íšŒ í…ŒìŠ¤íŠ¸ ì¤‘...")
    for i in range(3):
        start = time.time()
        file_path = system.downloader.download_face()
        elapsed = time.time() - start

        if file_path:
            download_times.append(elapsed)
            print(f"   ì‹œë„ {i+1}: {elapsed:.3f}ì´ˆ - ì„±ê³µ")
        else:
            print(f"   ì‹œë„ {i+1}: {elapsed:.3f}ì´ˆ - ì¤‘ë³µ ë˜ëŠ” ì‹¤íŒ¨")

        time.sleep(1)  # ì„œë²„ ë¶€í•˜ ë°©ì§€

    if download_times:
        avg_download = sum(download_times) / len(download_times)
        print(f"\n   ğŸ“Š í‰ê·  ë‹¤ìš´ë¡œë“œ ì‹œê°„: {avg_download:.3f}ì´ˆ")
        print(f"   ğŸ“Š ì²˜ë¦¬ëŸ‰: {1/avg_download:.2f} ì´ë¯¸ì§€/ì´ˆ\n")
    else:
        print(f"   âš ï¸  ìƒˆë¡œìš´ ë‹¤ìš´ë¡œë“œ ì—†ìŒ (ëª¨ë‘ ì¤‘ë³µ)\n")

    # 2. íŠ¹ì§• ì¶”ì¶œ ì„±ëŠ¥ ì¸¡ì •
    print("2ï¸âƒ£  íŠ¹ì§• ì¶”ì¶œ (Feature Extraction) ì„±ëŠ¥ ì¸¡ì •")
    print("-" * 70)
    analysis_times = []

    for i, file_path in enumerate(face_files[:5]):
        start = time.time()
        features = analyzer.analyze_face(str(file_path))
        elapsed = time.time() - start
        analysis_times.append(elapsed)
        print(f"   ì´ë¯¸ì§€ {i+1}: {elapsed:.4f}ì´ˆ")

    avg_analysis = sum(analysis_times) / len(analysis_times)
    print(f"\n   ğŸ“Š í‰ê·  íŠ¹ì§• ì¶”ì¶œ ì‹œê°„: {avg_analysis:.4f}ì´ˆ")
    print(f"   ğŸ“Š ì²˜ë¦¬ëŸ‰: {1/avg_analysis:.2f} ì´ë¯¸ì§€/ì´ˆ\n")

    # 3. ë²¡í„° ì„ë² ë”© ì„±ëŠ¥ ì¸¡ì •
    print("3ï¸âƒ£  ë²¡í„° ì„ë² ë”© (Embedding) ì„±ëŠ¥ ì¸¡ì •")
    print("-" * 70)
    embedding_times = []

    for i, file_path in enumerate(face_files[:5]):
        features = analyzer.analyze_face(str(file_path))

        start = time.time()
        embedding = embedder.create_embedding(str(file_path), features)
        elapsed = time.time() - start
        embedding_times.append(elapsed)
        print(f"   ì´ë¯¸ì§€ {i+1}: {elapsed:.4f}ì´ˆ (ì„ë² ë”© ì°¨ì›: {len(embedding)})")

    avg_embedding = sum(embedding_times) / len(embedding_times)
    print(f"\n   ğŸ“Š í‰ê·  ì„ë² ë”© ì‹œê°„: {avg_embedding:.4f}ì´ˆ")
    print(f"   ğŸ“Š ì²˜ë¦¬ëŸ‰: {1/avg_embedding:.2f} ì´ë¯¸ì§€/ì´ˆ\n")

    # 4. DB ì €ì¥ ì„±ëŠ¥ ì¸¡ì •
    print("4ï¸âƒ£  ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì„±ëŠ¥ ì¸¡ì •")
    print("-" * 70)
    db_save_times = []

    for i, file_path in enumerate(face_files[:5]):
        start = time.time()
        success = system.processor.process_face_file(str(file_path))
        elapsed = time.time() - start

        if success:
            db_save_times.append(elapsed)
            print(f"   ì´ë¯¸ì§€ {i+1}: {elapsed:.4f}ì´ˆ")
        else:
            print(f"   ì´ë¯¸ì§€ {i+1}: {elapsed:.4f}ì´ˆ (ì¤‘ë³µ ìŠ¤í‚µ)")

    if db_save_times:
        avg_db_save = sum(db_save_times) / len(db_save_times)
        print(f"\n   ğŸ“Š í‰ê·  DB ì €ì¥ ì‹œê°„: {avg_db_save:.4f}ì´ˆ")
        print(f"   ğŸ“Š ì²˜ë¦¬ëŸ‰: {1/avg_db_save:.2f} ì´ë¯¸ì§€/ì´ˆ\n")
    else:
        print(f"\n   âš ï¸  ëª¨ë“  ì´ë¯¸ì§€ê°€ ì´ë¯¸ DBì— ì¡´ì¬í•¨\n")

    # 5. ìœ ì‚¬ë„ ê²€ìƒ‰ ì„±ëŠ¥ ì¸¡ì •
    print("5ï¸âƒ£  ìœ ì‚¬ë„ ê²€ìƒ‰ (Vector Search) ì„±ëŠ¥ ì¸¡ì •")
    print("-" * 70)

    # ì¿¼ë¦¬ìš© ì„ë² ë”© ìƒì„±
    query_file = face_files[0]
    query_features = analyzer.analyze_face(str(query_file))
    query_embedding = embedder.create_embedding(str(query_file), query_features)

    search_times = []
    result_counts = [5, 10, 20, 50]

    for n_results in result_counts:
        start = time.time()
        results = system.db_manager.search_faces(query_embedding, n_results=n_results)
        elapsed = time.time() - start
        search_times.append(elapsed)
        print(f"   ìƒìœ„ {n_results}ê°œ ê²€ìƒ‰: {elapsed:.4f}ì´ˆ (ê²°ê³¼: {len(results)}ê°œ)")

    avg_search = sum(search_times) / len(search_times)
    print(f"\n   ğŸ“Š í‰ê·  ê²€ìƒ‰ ì‹œê°„: {avg_search:.4f}ì´ˆ")
    print(f"   ğŸ“Š ê²€ìƒ‰ ì²˜ë¦¬ëŸ‰: {1/avg_search:.2f} ì¿¼ë¦¬/ì´ˆ\n")

    # 6. ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ ì„±ëŠ¥ ì¸¡ì •
    print("6ï¸âƒ£  ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ ì„±ëŠ¥ ì¸¡ì •")
    print("-" * 70)

    metadata_filters = [
        {'skin_color': 'light'},
        {'age_group': 'adult'},
        {'hair_color': 'brown'}
    ]

    metadata_search_times = []

    for filter_dict in metadata_filters:
        start = time.time()
        results = system.db_manager.search_by_metadata(filter_dict, n_results=10)
        elapsed = time.time() - start
        metadata_search_times.append(elapsed)
        print(f"   í•„í„° {filter_dict}: {elapsed:.4f}ì´ˆ (ê²°ê³¼: {len(results)}ê°œ)")

    if metadata_search_times:
        avg_metadata_search = sum(metadata_search_times) / len(metadata_search_times)
        print(f"\n   ğŸ“Š í‰ê·  ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ ì‹œê°„: {avg_metadata_search:.4f}ì´ˆ")
        print(f"   ğŸ“Š ê²€ìƒ‰ ì²˜ë¦¬ëŸ‰: {1/avg_metadata_search:.2f} ì¿¼ë¦¬/ì´ˆ\n")

    # 7. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ëŠ¥ ì¸¡ì •
    print("7ï¸âƒ£  í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Vector + Metadata) ì„±ëŠ¥ ì¸¡ì •")
    print("-" * 70)

    hybrid_search_times = []

    for filter_dict in metadata_filters:
        start = time.time()
        results = system.db_manager.hybrid_search(query_embedding, filter_dict, n_results=10)
        elapsed = time.time() - start
        hybrid_search_times.append(elapsed)
        print(f"   ë²¡í„° + {filter_dict}: {elapsed:.4f}ì´ˆ (ê²°ê³¼: {len(results)}ê°œ)")

    if hybrid_search_times:
        avg_hybrid_search = sum(hybrid_search_times) / len(hybrid_search_times)
        print(f"\n   ğŸ“Š í‰ê·  í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œê°„: {avg_hybrid_search:.4f}ì´ˆ")
        print(f"   ğŸ“Š ê²€ìƒ‰ ì²˜ë¦¬ëŸ‰: {1/avg_hybrid_search:.2f} ì¿¼ë¦¬/ì´ˆ\n")

    # ì „ì²´ ìš”ì•½
    print("=" * 70)
    print("  ğŸ“Š ì„±ëŠ¥ ìš”ì•½")
    print("=" * 70)
    print()
    print(f"  1. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ:        {avg_download if download_times else 0:.3f}ì´ˆ ({1/avg_download if download_times else 0:.2f} img/s)")
    print(f"  2. íŠ¹ì§• ì¶”ì¶œ:             {avg_analysis:.4f}ì´ˆ ({1/avg_analysis:.2f} img/s)")
    print(f"  3. ë²¡í„° ì„ë² ë”©:           {avg_embedding:.4f}ì´ˆ ({1/avg_embedding:.2f} img/s)")

    if db_save_times:
        print(f"  4. DB ì €ì¥:               {avg_db_save:.4f}ì´ˆ ({1/avg_db_save:.2f} img/s)")
    else:
        print(f"  4. DB ì €ì¥:               N/A (ì¤‘ë³µ)")

    print(f"  5. ë²¡í„° ê²€ìƒ‰:             {avg_search:.4f}ì´ˆ ({1/avg_search:.2f} query/s)")
    print(f"  6. ë©”íƒ€ë°ì´í„° ê²€ìƒ‰:       {avg_metadata_search:.4f}ì´ˆ ({1/avg_metadata_search:.2f} query/s)")
    print(f"  7. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰:       {avg_hybrid_search:.4f}ì´ˆ ({1/avg_hybrid_search:.2f} query/s)")
    print()

    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œê°„
    total_pipeline = avg_analysis + avg_embedding + (avg_db_save if db_save_times else avg_analysis)
    print(f"  ğŸ“Œ ì „ì²´ íŒŒì´í”„ë¼ì¸ (ë¶„ì„+ì„ë² ë”©+ì €ì¥): {total_pipeline:.4f}ì´ˆ")
    print(f"  ğŸ“Œ ì „ì²´ ì²˜ë¦¬ëŸ‰: {1/total_pipeline:.2f} ì´ë¯¸ì§€/ì´ˆ")
    print()

    # ì‹œìŠ¤í…œ í†µê³„
    stats = system.stats.get_stats()
    print("=" * 70)
    print("  ğŸ“ˆ ì‹œìŠ¤í…œ í†µê³„")
    print("=" * 70)
    print(f"  ë‹¤ìš´ë¡œë“œ ì‹œë„: {stats['download_attempts']}")
    print(f"  ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {stats['download_success']}")
    print(f"  ë‹¤ìš´ë¡œë“œ ì¤‘ë³µ: {stats['download_duplicates']}")
    print(f"  ì²˜ë¦¬ ì™„ë£Œ: {stats['embed_processed']}")
    print(f"  ì„ë² ë”© ì„±ê³µ: {stats['embed_success']}")
    print(f"  ê²€ìƒ‰ ì¿¼ë¦¬: {stats['search_queries']}")
    print()

    # DB ì •ë³´
    db_info = system.db_manager.get_collection_info()
    print(f"  DB ì´ í•­ëª© ìˆ˜: {db_info.get('count', 0)}")
    print(f"  DB ê²½ë¡œ: {db_info.get('path', 'N/A')}")
    print()
    print("=" * 70)

if __name__ == "__main__":
    benchmark_performance()
