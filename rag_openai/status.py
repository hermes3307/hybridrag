#!/usr/bin/env python3
"""
ğŸ“Š Status Manager
Comprehensive status tracking and reporting for document processing
"""

import os
import json
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

@dataclass
class UrlStatus:
    """ğŸ“Œ URL ìš”ì²­ ìƒíƒœ ì •ë³´"""
    url: str
    requested_at: str
    documents_found: int
    total_size_mb: float
    status: str  # 'scanned', 'downloading', 'completed', 'failed'
    
@dataclass
class DownloadStatus:
    """ğŸ“¥ ë‹¤ìš´ë¡œë“œ ìƒíƒœ ì •ë³´"""
    total_files: int
    downloaded_files: int
    failed_files: int
    total_size_mb: float
    download_directory: str
    file_list: List[str]
    last_updated: str

@dataclass
class ChunkStatus:
    """ğŸ§© ì²­í‚¹ ìƒíƒœ ì •ë³´"""
    total_chunks: int
    total_characters: int
    files_processed: int
    processing_errors: List[str]
    chunk_size: int
    overlap: int
    semantic_chunking: bool
    last_updated: str

@dataclass
class VectorStatus:
    """ğŸ—„ï¸ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ì •ë³´"""
    is_ready: bool
    collection_name: str
    vector_count: int
    vector_dimensions: int
    index_size_mb: float
    embedding_model: str
    last_indexed: str
    search_capabilities: List[str]

class StatusManager:
    """ğŸ“Š ì „ì²´ ìƒíƒœ ê´€ë¦¬ì"""
    
    def __init__(self, status_file: str = "processing_status.json"):
        # ì ˆëŒ€ ê²½ë¡œë¡œ ì €ì¥í•˜ì—¬ ì–´ë””ì„œ ì‹¤í–‰í•´ë„ ê°™ì€ íŒŒì¼ ì‚¬ìš©
        self.status_file = os.path.abspath(status_file)
        self.current_status = {
            'url_history': [],
            'download_status': None,
            'chunk_status': None,
            'vector_status': None,
            'session_start': datetime.now().isoformat(),
            'last_updated': datetime.now().isoformat()
        }
        self._load_status()
        print(f"ğŸ“ Status file: {self.status_file}")
    
    def _load_status(self):
        """ğŸ’¾ ì €ì¥ëœ ìƒíƒœ ë¶ˆëŸ¬ì˜¤ê¸°"""
        try:
            if os.path.exists(self.status_file):
                with open(self.status_file, 'r', encoding='utf-8') as f:
                    saved_status = json.load(f)
                    self.current_status.update(saved_status)
        except Exception as e:
            logger.warning(f"ìƒíƒœ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _save_status(self):
        """ğŸ’¾ í˜„ì¬ ìƒíƒœ ì €ì¥"""
        try:
            self.current_status['last_updated'] = datetime.now().isoformat()
            with open(self.status_file, 'w', encoding='utf-8') as f:
                json.dump(self.current_status, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ìƒíƒœ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def update_url_status(self, url: str, documents_found: int, 
                         total_size_mb: float, status: str = 'scanned'):
        """ğŸ“Œ URL ìŠ¤ìº” ìƒíƒœ ì—…ë°ì´íŠ¸"""
        url_status = UrlStatus(
            url=url,
            requested_at=datetime.now().isoformat(),
            documents_found=documents_found,
            total_size_mb=total_size_mb,
            status=status
        )
        
        # ê¸°ì¡´ URLì´ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ì¶”ê°€
        url_history = self.current_status['url_history']
        for i, existing in enumerate(url_history):
            if existing.get('url') == url:
                url_history[i] = asdict(url_status)
                break
        else:
            url_history.append(asdict(url_status))
        
        # ìµœê·¼ 5ê°œë§Œ ìœ ì§€
        self.current_status['url_history'] = url_history[-5:]
        self._save_status()
    
    def update_download_status(self, total_files: int, downloaded_files: int, 
                             failed_files: int, total_size_mb: float,
                             download_directory: str, file_list: List[str]):
        """ğŸ“¥ ë‹¤ìš´ë¡œë“œ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        download_status = DownloadStatus(
            total_files=total_files,
            downloaded_files=downloaded_files,
            failed_files=failed_files,
            total_size_mb=total_size_mb,
            download_directory=download_directory,
            file_list=file_list,
            last_updated=datetime.now().isoformat()
        )
        
        self.current_status['download_status'] = asdict(download_status)
        self._save_status()
    
    def update_chunk_status(self, total_chunks: int, total_characters: int,
                           files_processed: int, processing_errors: List[str],
                           chunk_size: int, overlap: int, semantic_chunking: bool):
        """ğŸ§© ì²­í‚¹ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        chunk_status = ChunkStatus(
            total_chunks=total_chunks,
            total_characters=total_characters,
            files_processed=files_processed,
            processing_errors=processing_errors,
            chunk_size=chunk_size,
            overlap=overlap,
            semantic_chunking=semantic_chunking,
            last_updated=datetime.now().isoformat()
        )
        
        self.current_status['chunk_status'] = asdict(chunk_status)
        self._save_status()
    
    def update_vector_status(self, is_ready: bool, collection_name: str = "",
                           vector_count: int = 0, vector_dimensions: int = 0,
                           index_size_mb: float = 0, embedding_model: str = "",
                           search_capabilities: List[str] = None):
        """ğŸ—„ï¸ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        vector_status = VectorStatus(
            is_ready=is_ready,
            collection_name=collection_name,
            vector_count=vector_count,
            vector_dimensions=vector_dimensions,
            index_size_mb=index_size_mb,
            embedding_model=embedding_model,
            last_indexed=datetime.now().isoformat() if is_ready else "",
            search_capabilities=search_capabilities or []
        )
        
        self.current_status['vector_status'] = asdict(vector_status)
        self._save_status()
    
    def get_comprehensive_status(self) -> str:
        """ğŸ“Š ì¢…í•© ìƒíƒœ ë³´ê³ ì„œ ìƒì„±"""
        status = self.current_status
        report = []
        
        # ğŸ“ˆ ì„¸ì…˜ ì •ë³´
        report.append("ğŸš€ **Document Processing Session Status**")
        report.append(f"ğŸ• Session started: {self._format_datetime(status.get('session_start', ''))}")
        report.append(f"ğŸ”„ Last updated: {self._format_datetime(status.get('last_updated', ''))}")
        report.append("")
        
        # ğŸ“Œ URL íˆìŠ¤í† ë¦¬
        report.append("ğŸ“Œ **Recent URL Requests**")
        url_history = status.get('url_history', [])
        if url_history:
            for i, url_info in enumerate(reversed(url_history[-3:]), 1):
                report.append(f"   {i}. ğŸŒ {url_info['url']}")
                report.append(f"      ğŸ“„ Found: {url_info['documents_found']} documents")
                report.append(f"      ğŸ’¾ Size: {url_info['total_size_mb']:.1f} MB")
                report.append(f"      â° Requested: {self._format_datetime(url_info['requested_at'])}")
                report.append(f"      ğŸ“Š Status: {self._get_status_emoji(url_info['status'])} {url_info['status']}")
                report.append("")
        else:
            report.append("   âŒ No URLs requested yet")
            report.append("")
        
        # ğŸ“¥ ë‹¤ìš´ë¡œë“œ ìƒíƒœ
        report.append("ğŸ“¥ **Download Status**")
        download_status = status.get('download_status')
        if download_status:
            report.append(f"   ğŸ“Š Progress: {download_status['downloaded_files']}/{download_status['total_files']} files")
            if download_status['failed_files'] > 0:
                report.append(f"   âŒ Failed: {download_status['failed_files']} files")
            report.append(f"   ğŸ’¾ Total size: {download_status['total_size_mb']:.1f} MB")
            report.append(f"   ğŸ“ Directory: {download_status['download_directory']}")
            report.append(f"   ğŸ• Last update: {self._format_datetime(download_status['last_updated'])}")
            
            # íŒŒì¼ ëª©ë¡ (ìµœê·¼ 5ê°œ)
            file_list = download_status.get('file_list', [])
            if file_list:
                report.append("   ğŸ“‹ **Recent Files:**")
                for file_path in file_list[-5:]:
                    filename = os.path.basename(file_path)
                    report.append(f"      â€¢ {filename}")
                if len(file_list) > 5:
                    report.append(f"      ... and {len(file_list) - 5} more files")
        else:
            report.append("   âŒ No downloads completed yet")
        report.append("")
        
        # ğŸ§© ì²­í‚¹ ìƒíƒœ
        report.append("ğŸ§© **Chunking Status**")
        chunk_status = status.get('chunk_status')
        if chunk_status:
            report.append(f"   ğŸ“Š Chunks created: {chunk_status['total_chunks']:,}")
            report.append(f"   ğŸ“„ Files processed: {chunk_status['files_processed']}")
            report.append(f"   ğŸ“ Total characters: {chunk_status['total_characters']:,}")
            report.append(f"   âš™ï¸  Chunk size: {chunk_status['chunk_size']} characters")
            report.append(f"   ğŸ”— Overlap: {chunk_status['overlap']} characters")
            report.append(f"   ğŸ§  Semantic chunking: {'âœ… Enabled' if chunk_status['semantic_chunking'] else 'âŒ Disabled'}")
            report.append(f"   ğŸ• Last update: {self._format_datetime(chunk_status['last_updated'])}")
            
            # ì²˜ë¦¬ ì˜¤ë¥˜
            errors = chunk_status.get('processing_errors', [])
            if errors:
                report.append(f"   âš ï¸  Processing errors: {len(errors)}")
                for error in errors[-3:]:  # ìµœê·¼ 3ê°œ ì˜¤ë¥˜ë§Œ í‘œì‹œ
                    report.append(f"      â€¢ {error}")
        else:
            report.append("   âŒ No chunking completed yet")
        report.append("")
        
        # ğŸ—„ï¸ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ
        report.append("ğŸ—„ï¸ **Vector Database Status**")
        vector_status = status.get('vector_status')
        if vector_status and vector_status['is_ready']:
            report.append(f"   âœ… Status: Ready for search")
            report.append(f"   ğŸ“Š Collection: {vector_status['collection_name']}")
            report.append(f"   ğŸ”¢ Vector count: {vector_status['vector_count']:,}")
            report.append(f"   ğŸ“ Dimensions: {vector_status['vector_dimensions']}")
            report.append(f"   ğŸ’¾ Index size: {vector_status['index_size_mb']:.1f} MB")
            report.append(f"   ğŸ¤– Model: {vector_status['embedding_model']}")
            report.append(f"   ğŸ• Last indexed: {self._format_datetime(vector_status['last_indexed'])}")
            
            capabilities = vector_status.get('search_capabilities', [])
            if capabilities:
                report.append(f"   ğŸ” Search capabilities: {', '.join(capabilities)}")
        else:
            report.append("   âŒ Vector database not ready")
        report.append("")
        
        # ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ
        report.append("ğŸ’¡ **Suggested Next Steps**")
        next_steps = self._get_next_steps()
        for step in next_steps:
            report.append(f"   â€¢ {step}")
        
        return "\n".join(report)
    
    def get_quick_status(self) -> str:
        """âš¡ ê°„ë‹¨í•œ ìƒíƒœ ìš”ì•½"""
        status = self.current_status
        
        # ìµœê·¼ URL
        recent_url = "None"
        url_history = status.get('url_history', [])
        if url_history:
            recent_url = url_history[-1]['url']
        
        # ë‹¤ìš´ë¡œë“œ ìƒíƒœ
        download_info = "No downloads"
        download_status = status.get('download_status')
        if download_status:
            download_info = f"{download_status['downloaded_files']}/{download_status['total_files']} files"
        
        # ì²­í‚¹ ìƒíƒœ
        chunk_info = "No chunks"
        chunk_status = status.get('chunk_status')
        if chunk_status:
            chunk_info = f"{chunk_status['total_chunks']:,} chunks"
        
        # ë²¡í„° ìƒíƒœ
        vector_info = "âŒ Not ready"
        vector_status = status.get('vector_status')
        if vector_status and vector_status['is_ready']:
            vector_info = f"âœ… {vector_status['vector_count']:,} vectors"
        
        return f"""âš¡ **Quick Status**
ğŸŒ Last URL: {recent_url}
ğŸ“¥ Downloaded: {download_info}
ğŸ§© Chunked: {chunk_info}
ğŸ—„ï¸ Vector DB: {vector_info}"""
    
    def _format_datetime(self, iso_string: str) -> str:
        """ğŸ“… ë‚ ì§œ/ì‹œê°„ í¬ë§·íŒ…"""
        try:
            if iso_string:
                dt = datetime.fromisoformat(iso_string.replace('Z', '+00:00'))
                return dt.strftime("%Y-%m-%d %H:%M:%S")
        except:
            pass
        return "Unknown"
    
    def _get_status_emoji(self, status: str) -> str:
        """ğŸ“Š ìƒíƒœë³„ ì´ëª¨ì§€ ë°˜í™˜"""
        emoji_map = {
            'scanned': 'ğŸ”',
            'downloading': 'ğŸ“¥',
            'completed': 'âœ…',
            'failed': 'âŒ',
            'processing': 'âš™ï¸'
        }
        return emoji_map.get(status, 'â“')
    
    def _get_next_steps(self) -> List[str]:
        """ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ"""
        steps = []
        status = self.current_status
        
        # URL ìŠ¤ìº”ë˜ì§€ ì•Šì€ ê²½ìš°
        if not status.get('url_history'):
            steps.append("ğŸŒ Start by scanning a URL for documents")
            return steps
        
        # ë‹¤ìš´ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš°
        download_status = status.get('download_status')
        if not download_status or download_status['downloaded_files'] == 0:
            steps.append("ğŸ“¥ Download documents from the scanned URL")
            return steps
        
        # ì²­í‚¹ë˜ì§€ ì•Šì€ ê²½ìš°
        chunk_status = status.get('chunk_status')
        if not chunk_status or chunk_status['total_chunks'] == 0:
            steps.append("ğŸ§© Process downloaded files into chunks")
            return steps
        
        # ë²¡í„° ì¸ë±ì‹±ë˜ì§€ ì•Šì€ ê²½ìš°
        vector_status = status.get('vector_status')
        if not vector_status or not vector_status['is_ready']:
            steps.append("ğŸ—„ï¸ Index chunks into vector database")
            return steps
        
        # ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ
        steps.append("ğŸ” Ready to search documents!")
        steps.append("ğŸ“Š Check processing statistics")
        steps.append("ğŸŒ Process additional URLs")
        
        return steps
    
    def clear_status(self):
        """ğŸ—‘ï¸ ìƒíƒœ ì´ˆê¸°í™”"""
        self.current_status = {
            'url_history': [],
            'download_status': None,
            'chunk_status': None,
            'vector_status': None,
            'session_start': datetime.now().isoformat(),
            'last_updated': datetime.now().isoformat()
        }
        self._save_status()
    
    def export_status(self, filename: str = None) -> str:
        """ğŸ“¤ ìƒíƒœ ë‚´ë³´ë‚´ê¸°"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"status_report_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.current_status, f, ensure_ascii=False, indent=2)
            return f"ğŸ“ Status exported to {filename}"
        except Exception as e:
            return f"âŒ Export failed: {e}"