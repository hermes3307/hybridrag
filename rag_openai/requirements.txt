# ğŸ¤– Conversational Document Processing System
# Requirements and Setup Guide

## ğŸ“¦ Required Packages

# Core dependencies
sentence-transformers>=2.2.0
qdrant-client>=1.6.0
numpy>=1.21.0
aiohttp>=3.8.0
aiofiles>=22.1.0

# Document processing
PyMuPDF>=1.23.0         # For PDF processing
python-docx>=0.8.11     # For Word documents
docx2txt>=0.8           # For legacy .doc files (optional)

# Utilities
pathlib>=1.0.1
logging>=0.4.9.6
asyncio>=3.4.3
dataclasses>=0.8        # Python 3.7+ built-in
typing>=3.7.4           # Python 3.7+ built-in

## ğŸš€ Installation Commands

# Install all required packages:
pip install sentence-transformers qdrant-client numpy aiohttp aiofiles PyMuPDF python-docx

# Optional packages for enhanced functionality:
pip install docx2txt beautifulsoup4 lxml

## ğŸ“ File Structure

conversational_system/
â”œâ”€â”€ main.py                    # ğŸ¤– Main conversational interface
â”œâ”€â”€ web_downloader.py         # ğŸŒ Web document downloader
â”œâ”€â”€ smart_chunker.py          # ğŸ§© Intelligent document chunker
â”œâ”€â”€ vector_manager.py         # ğŸ—„ï¸ Vector store manager
â”œâ”€â”€ query_engine.py           # ğŸ” Conversational query engine
â”œâ”€â”€ requirements.txt          # ğŸ“¦ Package requirements
â”œâ”€â”€ downloaded_docs/          # ğŸ“¥ Downloaded documents folder
â”œâ”€â”€ qdrant_vector/           # ğŸ—„ï¸ Vector database storage
â””â”€â”€ README.md                # ğŸ“– Documentation

## ğŸ¯ Quick Start

1. Install dependencies:
   pip install -r requirements.txt

2. Run the conversational assistant:
   python main.py

3. Start chatting! Try these examples:
   - "Download PDFs from https://github.com/example/docs"
   - "Process the downloaded files"
   - "Search for database optimization"

## ğŸ’¡ Usage Examples

### Download Documents
- "Download documents from https://example.com/docs"
- "Get all PDFs from that GitHub repository"
- "Scan this URL for manuals"

### Process & Chunk
- "Chunk the downloaded files"
- "Process documents with 1000 character chunks"
- "Break files into semantic pieces"

### Search & Query
- "Search for database performance"
- "Find installation procedures"
- "What about SQL optimization?"

## âš™ï¸ Configuration Options

### Chunking Parameters
- chunk_size: Target size per chunk (default: 1000 characters)
- overlap: Overlap between chunks (default: 200 characters)
- use_semantic_splitting: Use intelligent paragraph breaks (default: True)

### Vector Store Settings
- model_name: Sentence transformer model (default: "paraphrase-multilingual-MiniLM-L12-v2")
- qdrant_path: Storage location (default: "./qdrant_vector")
- collection_name: Vector collection name (default: "conversation_docs")

### Download Settings
- download_dir: Where to save files (default: "downloaded_docs")
- max_concurrent: Concurrent downloads (default: 5)
- supported_formats: File types to process

## ğŸ”§ Troubleshooting

### Common Issues:

1. **PyMuPDF Installation Error**
   - Solution: pip install --upgrade pip && pip install PyMuPDF

2. **Qdrant Connection Issues**
   - Solution: Ensure qdrant_vector directory has write permissions

3. **Memory Issues with Large Documents**
   - Solution: Reduce batch_size in vector processing

4. **Encoding Errors**
   - Solution: System handles multiple encodings automatically

### System Requirements:
- Python 3.7+
- 4GB+ RAM (8GB+ recommended for large document sets)
- 2GB+ free disk space
- Internet connection for downloading models and documents

## ğŸŒŸ Features

âœ… Natural language conversation interface
âœ… Smart document discovery from URLs
âœ… Multi-format document processing (PDF, Word, Text, HTML)
âœ… Intelligent semantic chunking
âœ… Vector similarity search with Qdrant
âœ… Conversational query understanding
âœ… Multi-strategy search with result ranking
âœ… Rich metadata extraction and filtering
âœ… Progress tracking and error handling
âœ… Persistent vector storage

## ğŸš€ Advanced Usage

### Command Line Options
python main.py --help

### API Integration
The system can be imported and used programmatically:

```python
from main import ConversationalAssistant
import asyncio

async def main():
    assistant = ConversationalAssistant()
    response = await assistant.chat("Download PDFs from example.com")
    print(response)

asyncio.run(main())
```

### Batch Processing
For processing multiple URLs or document sets:

```python
urls = ["url1", "url2", "url3"]
for url in urls:
    response = await assistant.chat(f"Download documents from {url}")
    response = await assistant.chat("Process the files")
    response = await assistant.chat("Index into vector database")
```

## ğŸ“ Support

For issues or questions:
1. Check the troubleshooting section above
2. Review logs in the console output
3. Ensure all dependencies are properly installed
4. Verify file permissions for storage directories

## ğŸ”„ Updates

To update the system:
1. Pull latest changes
2. Update dependencies: pip install -r requirements.txt --upgrade
3. Restart the application

The system automatically handles data migration for vector stores.