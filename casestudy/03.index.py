import os
import json
import numpy as np
from tqdm import tqdm
import pandas as pd
from sentence_transformers import SentenceTransformer
import faiss
import re
import emoji

# 1. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
def load_case_studies(directory="case_studies"):
    """
    ì§€ì •ëœ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì½ì–´ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        directory (str): ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
        
    Returns:
        list: êµ¬ì¡°í™”ëœ ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    case_studies = []
    
    if not os.path.exists(directory):
        print(f"ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {directory}")
        return case_studies
    
    files = [f for f in os.listdir(directory) if f.endswith('.txt')]
    print(f"ì´ {len(files)}ê°œì˜ ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
    
    for filename in tqdm(files, desc="íŒŒì¼ ë¡œë”© ì¤‘"):
        file_path = os.path.join(directory, filename)
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # íŒŒì¼ëª…ì—ì„œ cateì™€ idx ì¶”ì¶œ
            cate_match = re.search(r'cate_(\d+)', filename)
            idx_match = re.search(r'idx_(\d+)', filename)
            
            cate = int(cate_match.group(1)) if cate_match else None
            idx = int(idx_match.group(1)) if idx_match else None
            
            # ë‚´ìš© íŒŒì‹±
            sections = {}
            
            # ì œëª© ì¶”ì¶œ
            title_match = re.search(r'ì œëª©:\s*(.*?)(?:\n\n|$)', content)
            title = title_match.group(1).strip() if title_match else "ì œëª© ì—†ìŒ"
            sections['title'] = title
            
            # ê° ì„¹ì…˜ ì¶”ì¶œ
            for section in ['Who', 'Problem', 'Solution', 'Results']:
                pattern = rf'{section}:\s*(.*?)(?:\n\n(?:[A-Za-z]+:|$)|$)'
                section_match = re.search(pattern, content, re.DOTALL)
                sections[section.lower()] = section_match.group(1).strip() if section_match else ""
            
            # ì‚°ì—… ë¶„ì•¼ ì¶”ì • (ì¹´í…Œê³ ë¦¬ ê¸°ë°˜)
            industry_map = {
                3: "í†µì‹ ",
                4: "ê¸ˆìœµ",
                5: "ì œì¡°",
                6: "ê³µê³µ",
                7: "ì„œë¹„ìŠ¤",
                8: "ê¸°íƒ€"
            }
            industry = industry_map.get(cate, "ê¸°íƒ€")
            
            # ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” êµ¬ì¡°í™”
            case_study = {
                'id': f"cate_{cate}_idx_{idx}",
                'filename': filename,
                'title': title,
                'who': sections['who'],
                'problem': sections['problem'],
                'solution': sections['solution'],
                'results': sections['results'],
                'full_text': content,
                'cate': cate,
                'idx': idx,
                'industry': industry,
                # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
                'emoji': get_industry_emoji(industry)
            }
            
            case_studies.append(case_study)
            
        except Exception as e:
            print(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {file_path}, ì˜¤ë¥˜: {str(e)}")
    
    print(f"{len(case_studies)}ê°œì˜ ì¼€ì´ìŠ¤ ìŠ¤í„°ë””ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    return case_studies

def get_industry_emoji(industry):
    """ì‚°ì—… ë¶„ì•¼ì— ë§ëŠ” ì´ëª¨ì§€ ë°˜í™˜"""
    emoji_map = {
        "í†µì‹ ": "ğŸ“±",
        "ê¸ˆìœµ": "ğŸ’°",
        "ì œì¡°": "ğŸ­",
        "ê³µê³µ": "ğŸ›ï¸",
        "ì„œë¹„ìŠ¤": "ğŸ›ï¸",
        "ê¸°íƒ€": "ğŸ“Š"
    }
    return emoji_map.get(industry, "ğŸ“„")

# 2. ë²¡í„° ì„ë² ë”© ìƒì„±
class CaseStudyVectorizer:
    def __init__(self, model_name="paraphrase-multilingual-MiniLM-L12-v2"):
        """
        ì¼€ì´ìŠ¤ ìŠ¤í„°ë””ë¥¼ ë²¡í„°í™”í•˜ëŠ” í´ë˜ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            model_name (str): ì‚¬ìš©í•  Sentence Transformer ëª¨ë¸ ì´ë¦„
        """
        print(f"ëª¨ë¸ {model_name} ë¡œë”© ì¤‘...")
        self.model = SentenceTransformer(model_name)
        self.vector_size = self.model.get_sentence_embedding_dimension()
        print(f"ë²¡í„° ì°¨ì›: {self.vector_size}")
    
    def vectorize_case_studies(self, case_studies):
        """
        ëª¨ë“  ì¼€ì´ìŠ¤ ìŠ¤í„°ë””ì˜ ì„¹ì…˜ë³„ ë²¡í„° ì„ë² ë”© ìƒì„±
        
        Args:
            case_studies (list): ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” ë¦¬ìŠ¤íŠ¸
            
        Returns:
            dict: ì„¹ì…˜ë³„ ë²¡í„° ì„ë² ë”©ê³¼ ì „ì²´ ë²¡í„° ì„ë² ë”©
        """
        print("ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” ë²¡í„°í™” ì¤‘...")
        
        # ê° ì„¹ì…˜ë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        sections = ['title', 'who', 'problem', 'solution', 'results']
        section_texts = {section: [] for section in sections}
        
        # ì „ì²´ í…ìŠ¤íŠ¸
        full_texts = []
        
        for case in case_studies:
            for section in sections:
                section_texts[section].append(case[section])
            
            # ì „ì²´ í…ìŠ¤íŠ¸ëŠ” ëª¨ë“  ì„¹ì…˜ì„ ê²°í•©
            combined_text = " ".join([case[section] for section in sections])
            full_texts.append(combined_text)
        
        # ê° ì„¹ì…˜ë³„ ë²¡í„°í™”
        vectors = {}
        for section in sections:
            print(f"{section} ì„¹ì…˜ ë²¡í„°í™” ì¤‘...")
            vectors[section] = self.model.encode(section_texts[section], show_progress_bar=True)
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ë²¡í„°í™”
        print("ì „ì²´ í…ìŠ¤íŠ¸ ë²¡í„°í™” ì¤‘...")
        vectors['full_text'] = self.model.encode(full_texts, show_progress_bar=True)
        
        return vectors

# 3. FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥
class CaseStudyVectorDB:
    def __init__(self, vector_size):
        """
        ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            vector_size (int): ë²¡í„°ì˜ ì°¨ì› í¬ê¸°
        """
        self.vector_size = vector_size
        self.indices = {}
        self.case_studies = []
    
    def build_indices(self, case_studies, vectors):
        """
        ì¼€ì´ìŠ¤ ìŠ¤í„°ë””ì™€ ë²¡í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ FAISS ì¸ë±ìŠ¤ êµ¬ì¶•
        
        Args:
            case_studies (list): ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” ë¦¬ìŠ¤íŠ¸
            vectors (dict): ì„¹ì…˜ë³„ ë²¡í„° ì„ë² ë”©
        """
        print("FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘...")
        self.case_studies = case_studies
        
        # ê° ì„¹ì…˜ë³„ ì¸ë±ìŠ¤ ìƒì„±
        for section, section_vectors in vectors.items():
            print(f"{section} ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
            index = faiss.IndexFlatL2(self.vector_size)  # L2 ê±°ë¦¬(ìœ í´ë¦¬ë“œ ê±°ë¦¬) ì‚¬ìš©
            if len(section_vectors) > 0:
                index.add(np.array(section_vectors).astype('float32'))
                self.indices[section] = index
    
    def save(self, directory="vector_db"):
        """
        ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            directory (str): ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        os.makedirs(directory, exist_ok=True)
        
        # ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” ë©”íƒ€ë°ì´í„° ì €ì¥
        with open(os.path.join(directory, 'case_studies.json'), 'w', encoding='utf-8') as f:
            json.dump(self.case_studies, f, ensure_ascii=False, indent=2)
        
        # FAISS ì¸ë±ìŠ¤ ì €ì¥
        for section, index in self.indices.items():
            index_path = os.path.join(directory, f"{section}_index.faiss")
            faiss.write_index(index, index_path)
        
        print(f"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ {directory}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    @classmethod
    def load(cls, directory="vector_db", vector_size=384):
        """
        ì €ì¥ëœ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ
        
        Args:
            directory (str): ë¡œë“œí•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
            vector_size (int): ë²¡í„° ì°¨ì› í¬ê¸°
            
        Returns:
            CaseStudyVectorDB: ë¡œë“œëœ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê°ì²´
        """
        if not os.path.exists(directory):
            raise FileNotFoundError(f"ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {directory}")
        
        # ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        instance = cls(vector_size)
        
        # ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” ë©”íƒ€ë°ì´í„° ë¡œë“œ
        with open(os.path.join(directory, 'case_studies.json'), 'r', encoding='utf-8') as f:
            instance.case_studies = json.load(f)
        
        # ê°€ëŠ¥í•œ ëª¨ë“  ì„¹ì…˜ ì¸ë±ìŠ¤ ì°¾ê¸°
        for filename in os.listdir(directory):
            if filename.endswith('_index.faiss'):
                section = filename.replace('_index.faiss', '')
                index_path = os.path.join(directory, filename)
                instance.indices[section] = faiss.read_index(index_path)
        
        return instance
    
    def search(self, query, section='full_text', k=5, vectorizer=None):
        """
        ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” ê²€ìƒ‰
        
        Args:
            query (str): ê²€ìƒ‰ ì¿¼ë¦¬ í…ìŠ¤íŠ¸
            section (str): ê²€ìƒ‰í•  ì„¹ì…˜ ('title', 'who', 'problem', 'solution', 'results', 'full_text')
            k (int): ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            vectorizer (CaseStudyVectorizer): ì¿¼ë¦¬ ë²¡í„°í™”ì— ì‚¬ìš©í•  ë²¡í„°ë¼ì´ì €
            
        Returns:
            list: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if section not in self.indices:
            raise ValueError(f"ì„¹ì…˜ '{section}'ì— ëŒ€í•œ ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        if vectorizer is None:
            raise ValueError("ì¿¼ë¦¬ ë²¡í„°í™”ë¥¼ ìœ„í•œ vectorizerê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ì¿¼ë¦¬ ë²¡í„°í™”
        query_vector = vectorizer.model.encode([query])[0].reshape(1, -1).astype('float32')
        
        # FAISSë¡œ ê²€ìƒ‰
        distances, indices = self.indices[section].search(query_vector, k)
        
        # ê²°ê³¼ êµ¬ì„±
        results = []
        for i, (distance, idx) in enumerate(zip(distances[0], indices[0])):
            if idx < len(self.case_studies):
                case = self.case_studies[idx]
                result = {
                    'rank': i + 1,
                    'distance': float(distance),
                    'similarity': 1.0 / (1.0 + float(distance)),  # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
                    'case_study': case
                }
                results.append(result)
        
        return results

# 4. ê²€ìƒ‰ ë° í‘œì‹œ ê¸°ëŠ¥
def format_search_results(results, highlight_query=None):
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ í˜•ì‹í™”
    
    Args:
        results (list): ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        highlight_query (str): í•˜ì´ë¼ì´íŠ¸í•  ì¿¼ë¦¬ (ì„ íƒ ì‚¬í•­)
        
    Returns:
        str: í˜•ì‹í™”ëœ ê²€ìƒ‰ ê²°ê³¼ ë¬¸ìì—´
    """
    if not results:
        return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    output = "# ğŸ” ê²€ìƒ‰ ê²°ê³¼\n\n"
    
    for result in results:
        case = result['case_study']
        similarity = result['similarity'] * 100
        
        industry_emoji = case.get('emoji', 'ğŸ“„')
        
        output += f"## {industry_emoji} {case['title']} (ìœ ì‚¬ë„: {similarity:.1f}%)\n\n"
        output += f"**ì‚°ì—…:** {case['industry']}\n"
        output += f"**ID:** {case['id']}\n\n"
        
        # ì„¹ì…˜ë³„ ë‚´ìš© í‘œì‹œ
        for section in ['who', 'problem', 'solution', 'results']:
            content = case[section]
            
            # ì¿¼ë¦¬ í•˜ì´ë¼ì´íŠ¸ (ì„ íƒ ì‚¬í•­)
            if highlight_query and highlight_query.strip():
                content = content.replace(highlight_query, f"**{highlight_query}**")
            
            section_emoji = {
                'who': 'ğŸ‘¥',
                'problem': 'â“',
                'solution': 'ğŸ’¡', 
                'results': 'âœ…'
            }
            
            emoji_icon = section_emoji.get(section, '')
            output += f"### {emoji_icon} {section.capitalize()}\n{content}\n\n"
        
        output += "---\n\n"
    
    return output

def interactive_search():
    """
    ëŒ€í™”í˜• ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰
    """
    # ì´ˆê¸° ë””ë ‰í† ë¦¬ ì„¤ì •
    source_dir = "case_studies"
    vector_db_dir = "vector_db"
    
    # í•„ìš”í•œ ì»´í¬ë„ŒíŠ¸ ë¡œë“œ
    print("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì¤‘...")
    
    # ë²¡í„° DB ë¡œë“œ ë„ìš°ë¯¸ í•¨ìˆ˜
    def load_vector_db():
        if not os.path.exists(vector_db_dir) or not os.listdir(vector_db_dir):
            print(f"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ({vector_db_dir})")
            print("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì˜µì…˜(7)ì„ ì„ íƒí•˜ì—¬ ë¨¼ì € ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ì„¸ìš”.")
            return None, None
            
        try:
            # ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
            model_name = "paraphrase-multilingual-MiniLM-L12-v2"
            
            # ë²¡í„°ë¼ì´ì € ì´ˆê¸°í™”
            vectorizer = CaseStudyVectorizer(model_name)
            
            # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ
            db = CaseStudyVectorDB.load(vector_db_dir, vectorizer.vector_size)
            print("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì™„ë£Œ!")
            return db, vectorizer
        except Exception as e:
            print(f"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None, None
    
    # ì´ˆê¸° ë¡œë“œ ì‹œë„
    db, vectorizer = load_vector_db()
    
    # ê²€ìƒ‰ ì˜µì…˜ í‘œì‹œ í•¨ìˆ˜
    def display_menu():
        print("\n========== ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” ê²€ìƒ‰ ì‹œìŠ¤í…œ ==========")
        print("ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
        print("1. 'ì „ì²´ í…ìŠ¤íŠ¸' - ëª¨ë“  ì„¹ì…˜ì—ì„œ ê²€ìƒ‰")
        print("2. 'ì œëª©' - ì œëª©ì—ì„œë§Œ ê²€ìƒ‰")
        print("3. 'ë¬¸ì œ' - Problem ì„¹ì…˜ì—ì„œë§Œ ê²€ìƒ‰")
        print("4. 'ì†”ë£¨ì…˜' - Solution ì„¹ì…˜ì—ì„œë§Œ ê²€ìƒ‰")
        print("5. 'ê²°ê³¼' - Results ì„¹ì…˜ì—ì„œë§Œ ê²€ìƒ‰")
        print("6. 'ë²¡í„° ë°ì´í„° ë¶„ì„' - ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ë° ì‹œê°í™”")
        print("7. 'ë²¡í„°ë°ì´í„° ì¬êµ¬ì¶•' - ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬êµ¬ì¶•")
        print("8. 'ì†ŒìŠ¤ ë””ë ‰í† ë¦¬ ì„¤ì •' - ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” ì†ŒìŠ¤ ë””ë ‰í† ë¦¬ ì„¤ì •")
        print("9. 'íƒ€ê²Ÿ ë²¡í„°ìŠ¤í† ì–´ ì„¤ì •' - ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ìœ„ì¹˜ ì„¤ì •")
        print("10. 'ë‚˜ê°€ê¸°' - í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
        print("í˜„ì¬ ì„¤ì •:")
        print(f"- ì†ŒìŠ¤ ë””ë ‰í† ë¦¬: {source_dir}")
        print(f"- ë²¡í„°ìŠ¤í† ì–´ ìœ„ì¹˜: {vector_db_dir}")
        print("=" * 50)
        

    def analyze_vector_data():
        if db is None or vectorizer is None:
            print("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("ì˜µì…˜ 7ì„ ì‚¬ìš©í•˜ì—¬ ë¨¼ì € ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ì„¸ìš”.")
            return
        
        print("\n========== ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ==========")
        
        # ê¸°ë³¸ í†µê³„ ì •ë³´ í‘œì‹œ
        total_cases = len(db.case_studies)
        print(f"ì´ ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” ìˆ˜: {total_cases}")
        print(f"ë²¡í„° ì°¨ì›: {vectorizer.vector_size}")
        
        # ì„¹ì…˜ë³„ ì¸ë±ìŠ¤ ì •ë³´
        print("\nì„¹ì…˜ë³„ ë²¡í„° ë°ì´í„°:")
        for section, index in db.indices.items():
            vector_count = index.ntotal
            print(f"- {section}: {vector_count}ê°œ ë²¡í„°")
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        industry_counts = {}
        category_counts = {}
        for case in db.case_studies:
            industry = case.get('industry', 'ë¯¸ë¶„ë¥˜')
            industry_counts[industry] = industry_counts.get(industry, 0) + 1
            
            cate = case.get('cate', 'ë¯¸ë¶„ë¥˜')
            category_counts[cate] = category_counts.get(cate, 0) + 1
        
        print("\nì‚°ì—…ë³„ ì¼€ì´ìŠ¤ ìˆ˜:")
        for industry, count in industry_counts.items():
            print(f"- {industry}: {count}ê°œ ({count/total_cases*100:.1f}%)")
        
        print("\nì¹´í…Œê³ ë¦¬ë³„ ì¼€ì´ìŠ¤ ìˆ˜:")
        for cate, count in category_counts.items():
            print(f"- ì¹´í…Œê³ ë¦¬ {cate}: {count}ê°œ ({count/total_cases*100:.1f}%)")
        
        # ìƒì„¸ ë¶„ì„ ì˜µì…˜ í‘œì‹œ
        print("\në°ì´í„° ì‹œê°í™” ì˜µì…˜:")
        print("1. ë²¡í„° ë¶„í¬ ì‹œê°í™” (2D)")
        print("2. ì‚°ì—…ë³„ ì¼€ì´ìŠ¤ ë¶„í¬")
        print("3. ì¹´í…Œê³ ë¦¬ë³„ ì¼€ì´ìŠ¤ ë¶„í¬")
        print("4. ì„¹ì…˜ë³„ ë°ì´í„° ê¸¸ì´ ë¶„ì„")
        print("5. ëŒì•„ê°€ê¸°")
        
        viz_option = input("\nì‹œê°í™” ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš” (1-5): ")
        
        try:
            import matplotlib
            import matplotlib.pyplot as plt
            import numpy as np
            
            # í•œê¸€ í°íŠ¸ ì„¤ì • ì‹œë„
            try:
                # ìœˆë„ìš°ì˜ ê²½ìš°
                if os.name == 'nt':
                    font_options = [
                        'Malgun Gothic',  # ë§‘ì€ ê³ ë”•
                        'Gulim',          # êµ´ë¦¼
                        'Batang',         # ë°”íƒ•
                        'Arial Unicode MS'
                    ]
                    
                    for font in font_options:
                        try:
                            plt.rcParams['font.family'] = font
                            test_text = 'í…ŒìŠ¤íŠ¸'
                            fig, ax = plt.subplots()
                            ax.text(0.5, 0.5, test_text)
                            fig.savefig('test_font.png')
                            plt.close(fig)
                            print(f"í•œê¸€ í°íŠ¸ '{font}' ì„¤ì • ì„±ê³µ")
                            break
                        except Exception:
                            continue
                
                # macOSì˜ ê²½ìš°
                elif sys.platform == 'darwin':
                    plt.rcParams['font.family'] = 'AppleGothic'
                    print("macOS í•œê¸€ í°íŠ¸ ì„¤ì •")
                
                # ë¦¬ëˆ…ìŠ¤ì˜ ê²½ìš°
                else:
                    plt.rcParams['font.family'] = 'NanumGothic'
                    print("Linux í•œê¸€ í°íŠ¸ ì„¤ì •")
                    
            except Exception as e:
                print(f"í•œê¸€ í°íŠ¸ ì„¤ì • ì‹¤íŒ¨: {str(e)}")
                print("ì˜ë¬¸ìœ¼ë¡œ ì‹œê°í™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.")
            
            # ì‹œê°í™” ì˜µì…˜ ì²˜ë¦¬
            if viz_option == '1':  # ë²¡í„° ë¶„í¬ ì‹œê°í™”
                print("\në²¡í„° ë¶„í¬ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.")
                
                # ì„¹ì…˜ ì„ íƒ
                print("ì‹œê°í™”í•  ì„¹ì…˜ì„ ì„ íƒí•˜ì„¸ìš”:")
                sections = list(db.indices.keys())
                for i, section in enumerate(sections):
                    print(f"{i+1}. {section}")
                
                section_idx = int(input("ì„ íƒ (ë²ˆí˜¸): ")) - 1
                if 0 <= section_idx < len(sections):
                    selected_section = sections[section_idx]
                    print(f"\n{selected_section} ì„¹ì…˜ì˜ ë²¡í„°ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.")
                    
                    # ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ë²¡í„° ìƒì„± (FAISS ì¸ë±ìŠ¤ ëŒ€ì‹ )
                    print("ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ë²¡í„°ë¥¼ ì¬ìƒì„±í•©ë‹ˆë‹¤.")
                    
                    # ì„¹ì…˜ë³„ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
                    section_texts = []
                    for case in db.case_studies:
                        if selected_section == 'full_text':
                            # ì „ì²´ í…ìŠ¤íŠ¸ëŠ” ëª¨ë“  ì„¹ì…˜ ê²°í•©
                            text = " ".join([case.get(s, "") for s in ['title', 'who', 'problem', 'solution', 'results']])
                        else:
                            text = case.get(selected_section, "")
                        section_texts.append(text)
                    
                    # ë²¡í„° ìƒì„±
                    print(f"{len(section_texts)}ê°œ í…ìŠ¤íŠ¸ì˜ ë²¡í„°ë¥¼ ìƒì„± ì¤‘...")
                    vectors = vectorizer.model.encode(section_texts, show_progress_bar=True)
                    
                    # PCAë¡œ ì°¨ì› ì¶•ì†Œ
                    from sklearn.decomposition import PCA
                    pca = PCA(n_components=2)
                    vectors_2d = pca.fit_transform(vectors)
                    
                    explained_variance = pca.explained_variance_ratio_
                    print(f"PCA ì„¤ëª…ëœ ë¶„ì‚°: {explained_variance[0]*100:.1f}%, {explained_variance[1]*100:.1f}%")
                    
                    # ê·¸ë˜í”„ ìƒì„±
                    plt.figure(figsize=(12, 10))
                    
                    # ì‚°ì—…ë³„ ìƒ‰ìƒ ë° ë§ˆì»¤ ì •ì˜
                    industry_colors = {
                        "í†µì‹ ": ("blue", "o"),      # ì›í˜•
                        "ê¸ˆìœµ": ("green", "s"),     # ì‚¬ê°í˜•
                        "ì œì¡°": ("red", "^"),       # ì‚¼ê°í˜•
                        "ê³µê³µ": ("purple", "d"),    # ë‹¤ì´ì•„ëª¬ë“œ
                        "ì„œë¹„ìŠ¤": ("orange", "v"),  # ì—­ì‚¼ê°í˜•
                        "ê¸°íƒ€": ("gray", "p")       # ì˜¤ê°í˜•
                    }
                    
                    # ì‚°ì—…ë³„ ë²¡í„° ê·¸ë£¹í™” ë° ê·¸ë¦¬ê¸°
                    industry_groups = {}
                    for i, (x, y) in enumerate(vectors_2d):
                        if i < len(db.case_studies):
                            industry = db.case_studies[i].get('industry', 'ê¸°íƒ€')
                            if industry not in industry_groups:
                                industry_groups[industry] = []
                            industry_groups[industry].append((x, y))
                    
                    # ì‚°ì—…ë³„ ê·¸ë£¹ ê·¸ë¦¬ê¸°
                    for industry, points in industry_groups.items():
                        if points:
                            points = np.array(points)
                            color, marker = industry_colors.get(industry, ("black", "o"))
                            plt.scatter(
                                points[:, 0], 
                                points[:, 1], 
                                label=f"{industry} ({len(points)}ê°œ)",
                                color=color,
                                marker=marker,
                                alpha=0.7,
                                s=100  # ì  í¬ê¸°
                            )
                    
                    # ì˜ë¬¸ ì œëª© ì‚¬ìš© (í•œê¸€ í°íŠ¸ ë¬¸ì œ ë°©ì§€)
                    section_names_en = {
                        'title': 'Title',
                        'who': 'Who',
                        'problem': 'Problem',
                        'solution': 'Solution',
                        'results': 'Results',
                        'full_text': 'Full Text'
                    }
                    
                    section_en = section_names_en.get(selected_section, selected_section)
                    plt.title(f"Vector Distribution of {section_en} Section (PCA 2D)")
                    plt.xlabel(f"Principal Component 1 ({explained_variance[0]*100:.1f}%)")
                    plt.ylabel(f"Principal Component 2 ({explained_variance[1]*100:.1f}%)")
                    plt.legend()
                    plt.grid(True, linestyle='--', alpha=0.7)
                    
                    # ì €ì¥ ë° í‘œì‹œ
                    viz_path = f"vector_visualization_{selected_section}.png"
                    plt.savefig(viz_path, dpi=300)
                    plt.close()
                    
                    print(f"ë²¡í„° ì‹œê°í™” ì´ë¯¸ì§€ê°€ '{viz_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
            elif viz_option == '2':  # ì‚°ì—…ë³„ ì¼€ì´ìŠ¤ ë¶„í¬
                print("\nì‚°ì—…ë³„ ì¼€ì´ìŠ¤ ë¶„í¬ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.")
                
                # íŒŒì´ ì°¨íŠ¸ ìƒì„±
                plt.figure(figsize=(10, 8))
                
                # ì‚°ì—…ë³„ ìƒ‰ìƒ ì •ì˜
                industry_colors = {
                    "í†µì‹ ": "blue",
                    "ê¸ˆìœµ": "green",
                    "ì œì¡°": "red",
                    "ê³µê³µ": "purple",
                    "ì„œë¹„ìŠ¤": "orange",
                    "ê¸°íƒ€": "gray"
                }
                
                # ë°ì´í„° ì¤€ë¹„
                industries = list(industry_counts.keys())
                counts = [industry_counts[industry] for industry in industries]
                colors = [industry_colors.get(industry, "black") for industry in industries]
                
                # íŒŒì´ ì°¨íŠ¸ ê·¸ë¦¬ê¸°
                plt.pie(
                    counts, 
                    labels=[f"{ind} ({cnt})" for ind, cnt in zip(industries, counts)],
                    colors=colors,
                    autopct='%1.1f%%',
                    startangle=90,
                    shadow=True,
                    explode=[0.05] * len(industries)  # ì•½ê°„ ë¶„ë¦¬
                )
                
                plt.title("Distribution of Case Studies by Industry")
                plt.axis('equal')  # ì›í˜• ìœ ì§€
                
                # ì €ì¥
                viz_path = "industry_distribution.png"
                plt.savefig(viz_path, dpi=300)
                plt.close()
                
                print(f"ì‚°ì—…ë³„ ë¶„í¬ ì‹œê°í™” ì´ë¯¸ì§€ê°€ '{viz_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
            elif viz_option == '3':  # ì¹´í…Œê³ ë¦¬ë³„ ì¼€ì´ìŠ¤ ë¶„í¬
                print("\nì¹´í…Œê³ ë¦¬ë³„ ì¼€ì´ìŠ¤ ë¶„í¬ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.")
                
                # ë§‰ëŒ€ ê·¸ë˜í”„ ìƒì„±
                plt.figure(figsize=(12, 8))
                
                # ë°ì´í„° ì¤€ë¹„
                categories = sorted(category_counts.keys())
                counts = [category_counts[cat] for cat in categories]
                
                # ë§‰ëŒ€ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
                bars = plt.bar(
                    categories, 
                    counts,
                    color='skyblue',
                    edgecolor='navy'
                )
                
                # ìˆ˜ì¹˜ í‘œì‹œ
                for bar in bars:
                    height = bar.get_height()
                    plt.text(
                        bar.get_x() + bar.get_width()/2.,
                        height + 0.5,
                        f'{int(height)}',
                        ha='center', 
                        va='bottom'
                    )
                
                plt.title("Distribution of Case Studies by Category")
                plt.xlabel("Category")
                plt.ylabel("Number of Cases")
                plt.xticks(rotation=45)
                plt.grid(axis='y', linestyle='--', alpha=0.7)
                
                # ì €ì¥
                viz_path = "category_distribution.png"
                plt.savefig(viz_path, dpi=300)
                plt.close()
                
                print(f"ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬ ì‹œê°í™” ì´ë¯¸ì§€ê°€ '{viz_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
            elif viz_option == '4':  # ì„¹ì…˜ë³„ ë°ì´í„° ê¸¸ì´ ë¶„ì„
                print("\nì„¹ì…˜ë³„ ë°ì´í„° ê¸¸ì´ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
                
                # ì„¹ì…˜ë³„ í…ìŠ¤íŠ¸ ê¸¸ì´ ê³„ì‚°
                sections = ['title', 'who', 'problem', 'solution', 'results']
                section_lengths = {section: [] for section in sections}
                
                for case in db.case_studies:
                    for section in sections:
                        text = case.get(section, "")
                        section_lengths[section].append(len(text))
                
                # ë°•ìŠ¤ í”Œë¡¯ ìƒì„±
                plt.figure(figsize=(14, 8))
                
                # ë°ì´í„° ì¤€ë¹„
                data = [section_lengths[section] for section in sections]
                
                # ì˜ë¬¸ ì„¹ì…˜ ì´ë¦„ (í•œê¸€ í°íŠ¸ ë¬¸ì œ ë°©ì§€)
                section_names_en = ['Title', 'Who', 'Problem', 'Solution', 'Results']
                
                # ë°•ìŠ¤ í”Œë¡¯ ê·¸ë¦¬ê¸°
                box = plt.boxplot(
                    data,
                    patch_artist=True,
                    labels=section_names_en,
                    notch=True,
                    whis=1.5
                )
                
                # ë°•ìŠ¤ ìƒ‰ìƒ ì„¤ì •
                colors = ['lightblue', 'lightgreen', 'salmon', 'violet', 'wheat']
                for patch, color in zip(box['boxes'], colors):
                    patch.set_facecolor(color)
                
                # í†µê³„ ì •ë³´ í‘œì‹œ
                for i, section in enumerate(sections):
                    lengths = section_lengths[section]
                    avg_len = sum(lengths) / len(lengths)
                    max_len = max(lengths)
                    min_len = min(lengths)
                    
                    plt.text(
                        i + 1,
                        max(lengths) + 5,
                        f'Avg: {avg_len:.1f}\nMax: {max_len}\nMin: {min_len}',
                        ha='center',
                        va='bottom',
                        fontsize=9,
                        bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8)
                    )
                
                plt.title("Length Distribution of Text by Section")
                plt.xlabel("Section")
                plt.ylabel("Character Count")
                plt.grid(axis='y', linestyle='--', alpha=0.7)
                
                # ì €ì¥
                viz_path = "section_length_analysis.png"
                plt.savefig(viz_path, dpi=300)
                plt.close()
                
                print(f"ì„¹ì…˜ë³„ ê¸¸ì´ ë¶„ì„ ì‹œê°í™” ì´ë¯¸ì§€ê°€ '{viz_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
            elif viz_option == '5':  # ëŒì•„ê°€ê¸°
                return
            else:
                print("ì˜¬ë°”ë¥¸ ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš” (1-5)")
                
        except ImportError as e:
            print(f"ì‹œê°í™”ì— í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {str(e)}")
            print("í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”: pip install matplotlib scikit-learn numpy")
        except Exception as e:
            print(f"ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            traceback.print_exc()
            

    while True:
        display_menu()
        search_option = input("ê²€ìƒ‰ ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš” (1-10): ")
        
        if search_option == '10':
            print("ê²€ìƒ‰ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        
        elif search_option == '6':
            analyze_vector_data()
            continue
        
        elif search_option == '7':
            print("\në²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì¬êµ¬ì¶•í•©ë‹ˆë‹¤...")
            try:
                build_vector_db(source_dir, vector_db_dir)
                print("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬êµ¬ì¶• ì™„ë£Œ!")
                # ìƒˆë¡œ êµ¬ì¶•ëœ DB ë¡œë“œ
                db, vectorizer = load_vector_db()
            except Exception as e:
                print(f"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            continue
            
        elif search_option == '8':
            new_source_dir = input(f"ìƒˆ ì†ŒìŠ¤ ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš” (í˜„ì¬: {source_dir}): ")
            if os.path.exists(new_source_dir):
                source_dir = new_source_dir
                print(f"ì†ŒìŠ¤ ë””ë ‰í† ë¦¬ê°€ '{source_dir}'ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                print(f"ì˜¤ë¥˜: ë””ë ‰í† ë¦¬ '{new_source_dir}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            continue
            
        elif search_option == '9':
            new_vector_db_dir = input(f"ìƒˆ ë²¡í„°ìŠ¤í† ì–´ ìœ„ì¹˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (í˜„ì¬: {vector_db_dir}): ")
            vector_db_dir = new_vector_db_dir
            print(f"ë²¡í„°ìŠ¤í† ì–´ ìœ„ì¹˜ê°€ '{vector_db_dir}'ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ìƒˆ ê²½ë¡œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì¡´ì¬í•˜ë©´ DB ë‹¤ì‹œ ë¡œë“œ
            if os.path.exists(vector_db_dir) and os.listdir(vector_db_dir):
                print("ìƒˆ ìœ„ì¹˜ì—ì„œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
                db, vectorizer = load_vector_db()
            else:
                print("ìƒˆ ìœ„ì¹˜ì—ëŠ” ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì˜µì…˜ 7ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì¶•í•˜ì„¸ìš”.")
                db, vectorizer = None, None
            continue
        
        # ê²€ìƒ‰ ê´€ë ¨ ì˜µì…˜ (1-5)
        section_map = {
            '1': 'full_text',
            '2': 'title',
            '3': 'problem',
            '4': 'solution',
            '5': 'results'
        }
        
        if search_option not in section_map:
            print("ì˜¬ë°”ë¥¸ ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš” (1-10)")
            continue
        
        # ë²¡í„° DBê°€ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
        if db is None or vectorizer is None:
            print("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("ì˜µì…˜ 7ì„ ì‚¬ìš©í•˜ì—¬ ë¨¼ì € ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ì„¸ìš”.")
            continue
        
        section = section_map[search_option]
        
        # ì¿¼ë¦¬ ì…ë ¥
        query = input("ê²€ìƒ‰í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”: ")
        if not query.strip():
            print("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            continue
        
        # ê²°ê³¼ ìˆ˜ ì…ë ¥
        try:
            k = int(input("ë°˜í™˜í•  ê²°ê³¼ ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ê¸°ë³¸ê°’: 3): ") or "3")
        except ValueError:
            k = 3
        
        # ê²€ìƒ‰ ì‹¤í–‰
        print(f"\n'{section}' ì„¹ì…˜ì—ì„œ '{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼:")
        try:
            results = db.search(query, section=section, k=k, vectorizer=vectorizer)
            
            if not results:
                print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # ê²°ê³¼ í‘œì‹œ
            for i, result in enumerate(results):
                case = result['case_study']
                similarity = result['similarity'] * 100
                
                industry_emoji = case.get('emoji', 'ğŸ“„')
                print(f"\n{i+1}. {industry_emoji} {case['title']} (ìœ ì‚¬ë„: {similarity:.1f}%)")
                print(f"   ì‚°ì—…: {case['industry']}")
                print(f"   ID: {case['id']}")
                
                # ìì„¸í•œ ì •ë³´ í‘œì‹œ ì—¬ë¶€
                show_details = input("   ìì„¸í•œ ì •ë³´ë¥¼ ë³´ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower() == 'y'
                if show_details:
                    for section_name in ['who', 'problem', 'solution', 'results']:
                        section_emoji = {
                            'who': 'ğŸ‘¥',
                            'problem': 'â“',
                            'solution': 'ğŸ’¡', 
                            'results': 'âœ…'
                        }
                        emoji_icon = section_emoji.get(section_name, '')
                        print(f"\n   {emoji_icon} {section_name.capitalize()}:")
                        print(f"   {case[section_name]}")
        except Exception as e:
            print(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


# ë©”ì¸ í•¨ìˆ˜: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•
def build_vector_db(case_studies_dir="case_studies", vector_db_dir="vector_db"):
    """
    ì¼€ì´ìŠ¤ ìŠ¤í„°ë””ë¥¼ ë¡œë“œí•˜ê³  ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
    
    Args:
        case_studies_dir (str): ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
        vector_db_dir (str): ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬
    """
    # 1. ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” ë¡œë“œ
    case_studies = load_case_studies(case_studies_dir)
    
    if not case_studies:
        print("ë¡œë“œëœ ì¼€ì´ìŠ¤ ìŠ¤í„°ë””ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # 2. ë²¡í„°ë¼ì´ì € ì´ˆê¸°í™” ë° ë²¡í„° ìƒì„±
    # ë‹¤êµ­ì–´ ì§€ì› ëª¨ë¸ ì‚¬ìš© (í•œêµ­ì–´ ì²˜ë¦¬ë¥¼ ìœ„í•´)
    vectorizer = CaseStudyVectorizer("paraphrase-multilingual-MiniLM-L12-v2")
    vectors = vectorizer.vectorize_case_studies(case_studies)
    
    # 3. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ë° ì €ì¥
    db = CaseStudyVectorDB(vectorizer.vector_size)
    db.build_indices(case_studies, vectors)
    db.save(vector_db_dir)
    
    print(f"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ {vector_db_dir}ì— ì„±ê³µì ìœ¼ë¡œ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ì´ {len(case_studies)}ê°œì˜ ì¼€ì´ìŠ¤ ìŠ¤í„°ë””ê°€ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return db, vectorizer




# ë©”ì¸ í•¨ìˆ˜: ì½”ë“œ ì‹¤í–‰ ë¶€ë¶„
if __name__ == "__main__":
    # ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±
    import argparse
    
    parser = argparse.ArgumentParser(description='Altibase ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” ë²¡í„° ê²€ìƒ‰ ì‹œìŠ¤í…œ')
    parser.add_argument('--build', action='store_true', help='ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•')
    parser.add_argument('--search', action='store_true', help='ëŒ€í™”í˜• ê²€ìƒ‰ ëª¨ë“œ ì‹¤í–‰')
    parser.add_argument('--input-dir', type=str, default='case_studies', help='ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” ë””ë ‰í† ë¦¬')
    parser.add_argument('--output-dir', type=str, default='vector_db', help='ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬')
    
    args = parser.parse_args()
    
    if args.build:
        build_vector_db(args.input_dir, args.output_dir)
    
    if args.search or not (args.build or args.search):
        interactive_search()

        

        