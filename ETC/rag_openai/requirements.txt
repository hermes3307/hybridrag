# 🤖 Conversational Document Processing System
# Requirements and Setup Guide

## 📦 Required Packages

# Core dependencies
sentence-transformers>=2.2.0
qdrant-client>=1.6.0
numpy>=1.21.0
aiohttp>=3.8.0
aiofiles>=22.1.0

# Document processing
PyMuPDF>=1.23.0         # For PDF processing
python-docx>=0.8.11     # For Word documents
docx2txt>=0.8           # For legacy .doc files (optional)

# Utilities
pathlib>=1.0.1
logging>=0.4.9.6
asyncio>=3.4.3
dataclasses>=0.8        # Python 3.7+ built-in
typing>=3.7.4           # Python 3.7+ built-in

## 🚀 Installation Commands

# Install all required packages:
pip install sentence-transformers qdrant-client numpy aiohttp aiofiles PyMuPDF python-docx

# Optional packages for enhanced functionality:
pip install docx2txt beautifulsoup4 lxml

## 📁 File Structure

conversational_system/
├── main.py                    # 🤖 Main conversational interface
├── web_downloader.py         # 🌐 Web document downloader
├── smart_chunker.py          # 🧩 Intelligent document chunker
├── vector_manager.py         # 🗄️ Vector store manager
├── query_engine.py           # 🔍 Conversational query engine
├── requirements.txt          # 📦 Package requirements
├── downloaded_docs/          # 📥 Downloaded documents folder
├── qdrant_vector/           # 🗄️ Vector database storage
└── README.md                # 📖 Documentation

## 🎯 Quick Start

1. Install dependencies:
   pip install -r requirements.txt

2. Run the conversational assistant:
   python main.py

3. Start chatting! Try these examples:
   - "Download PDFs from https://github.com/example/docs"
   - "Process the downloaded files"
   - "Search for database optimization"

## 💡 Usage Examples

### Download Documents
- "Download documents from https://example.com/docs"
- "Get all PDFs from that GitHub repository"
- "Scan this URL for manuals"

### Process & Chunk
- "Chunk the downloaded files"
- "Process documents with 1000 character chunks"
- "Break files into semantic pieces"

### Search & Query
- "Search for database performance"
- "Find installation procedures"
- "What about SQL optimization?"

## ⚙️ Configuration Options

### Chunking Parameters
- chunk_size: Target size per chunk (default: 1000 characters)
- overlap: Overlap between chunks (default: 200 characters)
- use_semantic_splitting: Use intelligent paragraph breaks (default: True)

### Vector Store Settings
- model_name: Sentence transformer model (default: "paraphrase-multilingual-MiniLM-L12-v2")
- qdrant_path: Storage location (default: "./qdrant_vector")
- collection_name: Vector collection name (default: "conversation_docs")

### Download Settings
- download_dir: Where to save files (default: "downloaded_docs")
- max_concurrent: Concurrent downloads (default: 5)
- supported_formats: File types to process

## 🔧 Troubleshooting

### Common Issues:

1. **PyMuPDF Installation Error**
   - Solution: pip install --upgrade pip && pip install PyMuPDF

2. **Qdrant Connection Issues**
   - Solution: Ensure qdrant_vector directory has write permissions

3. **Memory Issues with Large Documents**
   - Solution: Reduce batch_size in vector processing

4. **Encoding Errors**
   - Solution: System handles multiple encodings automatically

### System Requirements:
- Python 3.7+
- 4GB+ RAM (8GB+ recommended for large document sets)
- 2GB+ free disk space
- Internet connection for downloading models and documents

## 🌟 Features

✅ Natural language conversation interface
✅ Smart document discovery from URLs
✅ Multi-format document processing (PDF, Word, Text, HTML)
✅ Intelligent semantic chunking
✅ Vector similarity search with Qdrant
✅ Conversational query understanding
✅ Multi-strategy search with result ranking
✅ Rich metadata extraction and filtering
✅ Progress tracking and error handling
✅ Persistent vector storage

## 🚀 Advanced Usage

### Command Line Options
python main.py --help

### API Integration
The system can be imported and used programmatically:

```python
from main import ConversationalAssistant
import asyncio

async def main():
    assistant = ConversationalAssistant()
    response = await assistant.chat("Download PDFs from example.com")
    print(response)

asyncio.run(main())
```

### Batch Processing
For processing multiple URLs or document sets:

```python
urls = ["url1", "url2", "url3"]
for url in urls:
    response = await assistant.chat(f"Download documents from {url}")
    response = await assistant.chat("Process the files")
    response = await assistant.chat("Index into vector database")
```

## 📞 Support

For issues or questions:
1. Check the troubleshooting section above
2. Review logs in the console output
3. Ensure all dependencies are properly installed
4. Verify file permissions for storage directories

## 🔄 Updates

To update the system:
1. Pull latest changes
2. Update dependencies: pip install -r requirements.txt --upgrade
3. Restart the application

The system automatically handles data migration for vector stores.